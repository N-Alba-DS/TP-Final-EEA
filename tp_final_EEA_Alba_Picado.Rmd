---
title: "eea2024_tp1_alba_nahuel"
output: html_notebook
---


# Practico 1

## Preparación
```{r setup}

knitr::opts_chunk$set(echo = TRUE, root.dir = "C:/Users/Admin/Documents/1_Notebook/1_Estudio/1_UBA_Maestria_DS/1_Especializacion/1_Segundo_Semestre/EEA/TP_1/eea2024_tp1_alba_nahuel.Rmd")
knitr::opts_chunk$set(echo = TRUE)

```

### Librerías 
```{r}
# install.packages(c(
#   "tidyverse",
#   "rmarkdown",
#   "readxl",
#   "readr",
#   "moments",
#   "ggmap",
#   "tmap",
#   "tmaptools",
#   "factoextra",
#   "corrplot",
#   "reshape2",
#   "knitr",
#   "plotly",
#   "htmltools",
#   "htmlwidgets",
#   "leaflet",
#    "ggplot2",
#    "ggthemes",
#     "ggrepel" 
#      "car"
# ))
```


```{r setup2}

library(GGally)
library(dplyr)
library(tidyverse)
library (rmarkdown)
library(readxl)
library(readr)
library (moments)
library(ggmap)
library(ggplot2)
library(ggthemes)  
library(ggrepel) 
library(GGally)
library(scales)  
library (tmap)
library (tmaptools)
library(factoextra)
library(corrplot)
library(reshape2)
library(corrplot)
library (knitr)
library (tidymodels)
library (lmtest)
library (car)
library(purrr)
library(ggridges)
library (robustbase)

```



### Carga 

```{r} 

df_train <- read.csv("C:\\Users\\Admin\\Documents\\1_Notebook\\1_Estudio\\1_UBA_Maestria_DS\\1_Especializacion\\1_Segundo_Semestre\\EEA\\TP_1\\Datasets\\eph_train_2023.csv")



```

## Consigna 1 

```{r}
glimpse(df_train)
```
El dataset presenta una estructura de 11772 filas y 20 columnas. El formato de las variables presenta 3 formatos distintos, siendo 10 variables formato chr (character): "codusu", "region",  "fecha_nacimiento", "asistencia_educacion", "nivel_ed", "tipo_establecimiento", "sexo", "categoria_ocupacion", "cat_cantidad_empleos", "alfabetismo". 
Hay otras 9 variables formato int (datos numéricos de tipo entero): "ano4" , "trimestre", "aglomerado", "edad", "codigo_actividad", "salario", "horas_trabajadas", "educacion", "experiencia_potencial". 
Finalmente, hay 1 variable formato dbl(double) que representa los números flotantes nominada como "salario_horario".

```{r}
tabla_exploratorios =  df_train %>% gather(., 
                                            key = "variables", 
                                            value = "valores") %>% # agrupamos por las variables del set
                                      group_by(variables) %>% 
                                      summarise(valores_unicos = n_distinct(valores),
                                      porcentaje_faltantes = sum(is.na(valores))/nrow(df_train)*100) %>% 
                                      arrange(desc(porcentaje_faltantes), valores_unicos) # ordenamos por porcentaje de faltantes y valores unicos
tabla_exploratorios
```
El dataset en general no presenta presencia de nulos salvo en las variables de asistencia_educación con un porcentaje de nulos representativo del 0.0084%

```{r, visible = TRUE}

df_c1 <- df_train %>%
  select_if(is.integer) %>%
  select(-ano4, -trimestre, -aglomerado, -codigo_actividad) %>%
  bind_cols(df_train %>% select(sexo)) %>%
  mutate(salario_horario = df_train$salario_horario)


grafico = ggpairs (df_c1, mapping = aes(color = sexo))
grafico

```

Para hacer significativo el análisis de las variables numéricas se retiraron las variables año, trimestre, aglomerado, código de actividad. Asimismo se incluyo sexo para preliminarmente poder observar patrones del problema a tratar en relación con el salario_horario. 


```{r}
corr_matrix <- cor(df_c1 %>% select(-sexo), use = "complete.obs")


library(reshape2)
corr_melt <- melt(corr_matrix)


ggplot(data = corr_melt, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Correlación") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1)) +
  coord_fixed()
```


Se observa una lógica correlación fuerte entre la edad y la experiencia, reflejado no sólo en el heatmap de la matriz de correlación sino también en la distribución con correlación lineal positiva del scatterplot matrix, que devuelve valores de correlación (0.963), lo que es esperable, ya que la experiencia laboral aumenta con la edad.
La matriz de correlación del heatmap muestra una moderada correlación positiva entre salario y educación y leve correlación entre salario y edad. Asimismo resulta lógico una leve correlación entre salario y horas trabajadas en la medida que indica que hay gente tendrá salarios más grandes trabajando lo mismo que otras personas.
Conforme surge del scatterplot matrix sexo influye en varias variables, mostrando diferencias visibles en salario_horario, donde los hombres parecen tener una mayor dispersión y un salario ligeramente mayor que las mujeres.
Finalmente centrándonos sólo en salario horario hay una correlacion fuerte y lógica entre salario y salario_horario, y una correlación negativa con horas trabajadas, lo cual es consecuente con el hecho de que si se trabaja menos horas el salario será menor y consecuentemente también el salario horario, pero es leve indicando que no todo el mundo cobra lo mismo por hora. Asimismo hay mínima interacción entre salario horario y experiencia.




## Consigna 2



```{r}
#Ajuste modelo
modelo_edad = lm(formula = salario_horario ~ experiencia_potencial, data = df_c1)
summary(modelo_edad)

```

```{r}
df_c1 = df_c1 %>%  mutate (exp_pot_2 = experiencia_potencial ** 2)
```


```{r}
modelo_edad_2 = lm(formula = salario_horario ~ experiencia_potencial + exp_pot_2, data = df_c1)
summary(modelo_edad_2)
```

```{r}
ggplot(data = df_c1, aes(x =  exp_pot_2, color = sexo, y= salario_horario)) +
  geom_point(alpha = 0.75) + # agregamos transparencia a los puntos
  labs(title = "relación entre exp_pot al cuadrado y salario_horario") + 
  theme(legend.position = 'none')  
```
### Respuesta 

En el caso del modelo 1, el aumento en una unidad de la variable experiencia_potencial se traduce en un aumento de  2.3743 pesos en el salario. Por otro lado, en el modelo dos dicho valor muta a 26.9 pesos en el salario. 

Tomando el modelo 2 como base, para el caso de que la persona tuviera 6 años de experiencia laboral la misma tendría un aumento de 158.85 pesos como producto de: (161.796 - 2.916)=158.85; y para el supuesto de un trabajador de 35 años de antigüedad 926.8 pesos como producto de: (943.81-17.01)=926.8.

Se observa entonces que si bien la experiencia produce un aumento del salario_horario el coeficiente negativo en la variable exp_pot_2 sería indicativo de que a medida que el valor cuadrático de la experiencia aumenta, el salario horario tiende a disminuir ligeramente. Esto podría sugerir que el efecto de la experiencia en el salario tiene una forma no lineal, donde después de cierto punto, el aumento en la experiencia no continúa incrementando el salario de manera lineal, e incluso podría reducirlo como lo ratifica el siguiente gráfico de dispersión que muestra una correlación negativa 

## Consigna 3 

### Interpretación de los coeficientes

```{r}
df_c3 = df_c1
df_c3 = df_c3 %>% mutate(sexo = if_else(sexo == "Mujer", TRUE, FALSE)) %>%  mutate(sexo_x_años_ed = sexo * educacion)
```


```{r}
#Ajuste de modelo
modelo_edad_3 = lm(formula = salario_horario ~ educacion +experiencia_potencial + exp_pot_2 + sexo + sexo_x_años_ed, data = df_c3)

#Creacion de gráfico
intercepto_hombres <- modelo_edad_3$coefficients[1]  
intercepto_mujeres <- modelo_edad_3$coefficients[1] + modelo_edad_3$coefficients[5] 
pendiente_educacion <- modelo_edad_3$coefficients[2]  
pendiente_experiencia <- modelo_edad_3$coefficients[3]  
pendiente_experiencia_cuadrado <- modelo_edad_3$coefficients[4] 

color_group <- c("blue", "red")

modelo_edad_3 %>%
  ggplot(aes(x = educacion, y = salario_horario)) + 
  geom_point(aes(color = as.factor(sexo)), alpha=0.5) + 
  geom_abline(intercept = intercepto_hombres, slope = pendiente_educacion, color = "blue", size=1) + 
  geom_abline(intercept = intercepto_mujeres, slope = pendiente_educacion, color = "red", size=1) + 
  theme_bw() +
  labs(title = "Modelo Lineal: Efecto de la Educación en el Salario por Sexo", 
       x = "Años de Educación", 
       y = "Salario", 
       color = "Sexo") +
  scale_color_manual(values = color_group)

```
```{r}
summary(modelo_edad_3)
```
Sin perjuicio de el análisis realizado en el subpunto "Diagnóstico del modelo" que revela las falencias del modelo, se aclara anticipadamente que los estimadores pueden parecer significativos según los p-valores obtenidos, pero debido a la heterocedasticidad y otros problemas (que se analizan en el punto correspondiente), no son eficientes y las pruebas de significancia pueden ser engañosas.

No obstante ello, el modelo indica que la educación y la experiencia tienen un efecto positivo y significativo para explicar el salario horario, mientras que la experiencia cuadrática también es significativa pero muestra una disminución en la tasa de crecimiento del salario. Esto podría sugerir que a medida que la experiencia aumenta también lo hará el salario_horario pero llegado un punto el aumento de la experiencia no necesariamente ocasiona un aumento sino un decrecimiento del salario. El coeficiente negativo y significativo para sexoTRUE sugiere una ligera disparidad de género en el salario que se ratifica en el gráfico "Modelo Lineal: Efecto de la Educación en el Salario por Sexo". Sin embargo, la interacción entre el sexo y la educación no es significativa con un P-value de 0.162, lo que indica que el impacto de la educación sobre el salario no difiere mucho entre hombres y mujeres. El bajo R² de 16.71% sugiere que otros factores no incluidos en el modelo pueden influir significativamente en el salario horario y que por ende el modelo explica poca variabilidad de la variable dependiente.

Remarco que si bien el Adjusted R-squared 0.1668 indica que la inclusión de nuevas variables mejoró el modelo comparado con la consigna 2 todavía continua en valores bajos (16.68%) para explicar la variabilidad total de la variable dependiente.

### Diagnóstico del modelo 
```{r}
plot (modelo_edad_3)
anova(modelo_edad_3)
```
```{r}
residuos = residuals(modelo_edad_3)
media_residuos = mean(residuos)
glimpse (residuos)

```
```{r}
hist(residuos, breaks=30, main="Histograma de los Residuos", xlab="Residuos")
```
```{r}
bptest(modelo_edad_3)
```
```{r}
media_residuos
```

```{r}
umbral_leverage = 6*2/11772
```


```{r}
distancia_cook <- cooks.distance(modelo_edad_3)

head(distancia_cook)

distancia_cook[7797]


```
```{r}
durbinWatsonTest(modelo_edad_3)
```
```{r}
vif(modelo_edad_3)
```
Residuals vs fitted: EL diagnóstico del modelo revela que no hay una distribución aleatoria en torno a 0, sino que los datos se abren en patrón de abanico lo cual sugeriría que no se satisface el supuesto de heterocedasticidad.

Q-Q Residuals: revela que los residuos no siguen una distribución normal especialmente en la cola derecha que se aleja de los valores de los cuantiles con distribución normal del eje X. Cabe remarcar que la normalidad no es un supuesto crucial en la medida que por una versión extendida del teorema Central del Límite se garantiza que el estimador de mínimos cuadrados de la pendiente tenga distribución de muestreo aproximadamente normal dado que la muestra en este caso esta compuesta por 11772 observaciones.


Leverage vs Residuals: revela varios registros con valores de leverage que superan el umbral de leverage promedio aceptable para el modelo de 0.001 calculado teniendo en consideración que hay 6 variables y 11772 observaciones. Siendo especialmente preocupante el 11772 que si bien revela un valor de 0.02806894 el mismo posee un leverage alto y gran cantidad de residuos, pudiendo incluso sugerir que ya ha influido en el ajuste del modelo y por ende sus residuos podrían ser incluso mayores en una posición de alto leverage.

Conclusión del diagnóstico del modelo: salvo el supuesto de independencia de los residuos que podría quedar ratificado por el test de Durbin-Watson, con un correpsondiente estadístico de 1.972 muy cercano a 2 (valor de máxima independecia), pero con un valor sin suficiente p-value (0.128) como para invalidar la hipotesis 0 de que los errores son independientes, el modelo en general incumple con los supuestos esperables para un modelo de regresión lineal múltiple dado que sus residuos presentan heterocedasticidad, con una distribución no normal y con la presencia de multicolinealidad segun el VIF en las variables experiencia_potencial, exp_pot_2,sexo,sexo_x_años_ed. Como consecuencia el modelo es no eficiente.  Por ende aunque los coeficientes son significativos, las varianzas de los errores estándar no son las más pequeñas posibles, lo que afecta la precisión y confiabilidad del modelo. 

## Consigna 4

### Interpretación del modelo 

```{r}
df_c4 = df_c3 
df_c4 = df_c4 %>% mutate(log_salario_horario = log(salario_horario))
```

```{r}
#Ajuste de modelo
modelo_c4 = lm(formula = log_salario_horario ~ educacion +experiencia_potencial + exp_pot_2 + sexo + sexo_x_años_ed, data = df_c4)
summary(modelo_c4)
```
```{r}
residuos_c4 = residuals(modelo_c4)
hist(residuos_c4, breaks=30, main="Histograma de los Residuos", xlab="Residuos")
```
```{r}
tidy_sc_pt <- tidy(modelo_c4, conf.int = TRUE) %>% arrange(p.value)
tidy_sc_pt
```
```{r}
tidy_sc_pt <- tidy(modelo_edad_3, conf.int = TRUE) %>% arrange(p.value)
tidy_sc_pt
```
```{r}
ggplot(tidy_sc_pt, aes(estimate, term, xmin = conf.low, xmax = conf.high, height = 0)) +
  geom_point(color = "forestgreen",size=2) +
  geom_vline(xintercept = 0, lty = 4, color = "black") +
  geom_errorbarh(color = "forestgreen", size=1) +
  theme_bw() +
  labs(y = "Coeficientes β", x = "Estimación")
```


Este modelo se diferencia del anterior en la medida que es un modelo Log-Nivel, donde el coeficiente de la variable independiente se interpreta como la semielasticidad de la variable dependiente respecto a las variables independientes. Es decir un aumento de una unidad (1 año) adicional en educación manteniendo todas las demás variables en el caso concreto representa un aumento del 8,4% respecto del salario horario. Se observa cambio en la significatividad de los coeficientes, específicamente de sexo_x_años_ed que pasó de un p-value de 0.162 a 0.00064 siendo áltamente significativo. 
El presente modelo presenta R-squared de 0.1936, es decir explica el 19.36% de la variabilidad total de la variable dependiente que en la medida que presenta la misma cantidad de variables independientes que el anterior nos resulta como medida idonea para afirmar que el modelo a mejorado un 2.65%.

### Diagnóstico del modelo

```{r}
plot(modelo_c4)
```





```{r}
distancia_cook <- cooks.distance(modelo_c4)


d1 = distancia_cook[7797]
d2 = distancia_cook[5515]
d3 =distancia_cook[8678]

cat("d1:", d1, "d2:", d2, "d3:", d3, "\n")

```

```{r}
durbinWatsonTest(modelo_c4)

```

```{r}
vif(modelo_c4)
```
Residuals vs Fitted: En el gráfico la dispersión de los puntos parece bastante uniforme alrededor de la línea de residuos cero lo que indica que la varianza es constante a lo largo de los valores predichos, por lo que hay un indicio de homocedasticidad. Esto resulta lógico en la medida que la transformación logarítmica de la Y induce varianza constante en la escala transformada, lo cual queda acreditado por el cambio que se presenta en la distribución de los residuos en comparación con el modelo de la consigna 3. En el modelo 3 la distribución de los residuos muestra una asimetría considerable hacia la derecha y una gran cantidad de valores extremos, lo que indica la presencia de valores atípicos y heterocedasticidad dado que los errores no muestran varianza constante. En el modelo 4, la distribución de los residuos se ha vuelto más simétrica y parece seguir una distribución mucho más cercana a la normalidad y más cercana a la homocedasticidad.

Q-Q Residuals: En concordancia con lo antedicho, la mayoría de los puntos en el rango central del gráfico están alineados bastante bien a lo largo de la línea diagonal, lo que sugiere que la mayoría de los residuos siguen una distribución aproximadamente normal, regularizandose sobre todo los valores relativos a la cola extrema de la derecha.

Residuals vs Leverage:  se mantiene la observación 7797 (también presente en el modelo 3) como posible observación influyente, sin embargo disminuye su valor de de distanciua de cook a 0.016. Asimismo aparecen como llamativos los puntos 8678 y 5515 de valores 0.023 y 0.007 que si bien parecerían no influyentes por su alto leverage que sobrepasan punto de corte o límite de leverage de 0.001 motivo por el cuál son susceptibles de ser influyentes

Diagnóstico del modelo: Hay una ligera correlación positiva entre los residuos con un p-value de 0.01, la magnitud de la autocorrelación es pequeña que queda acredita por el test de Durbin-Watson, ahora sí con p-valor significativo.  Asimismo, si bien el gráfico de Q-Q Residuals tiende a tener un comportamiento más normal no se cumplen los requisitos de normallidad por el alejamiento de la cola izquierda del gráfico Q-Q Residuals, pero sí el requisito de homocedasticidad. 

## Consigna 5

```{r}

df_test = read.csv("C:/Users/Admin/Documents/1_Notebook/1_Estudio/1_UBA_Maestria_DS/1_Especializacion/1_Segundo_Semestre/EEA/TP_1/Datasets/eph_test_2023.csv")

```

### Analisis de interacción de variables y planteo de los modelos 


```{r}
#Creacion de los dos nuevos modelos
modelo_educacion = lm(formula = log(salario_horario) ~ educacion*nivel_ed + asistencia_educacion * experiencia_potencial + experiencia_potencial + I(experiencia_potencial^2) + sexo + sexo*educacion, data = df_train)

modelo_experiencia = lm(formula = log(salario_horario) ~ experiencia_potencial*categoria_ocupacion + experiencia_potencial*tipo_establecimiento + experiencia_potencial + I(experiencia_potencial^2) + sexo + sexo*educacion , data = df_train)

```


```{r}
lista_modelos = list(modelo_educacion = modelo_educacion, modelo_experiencia = modelo_experiencia, modelo_c4 = modelo_c4, modelo_edad_3= modelo_edad_3)
df_c5 = map_df(lista_modelos, glance, .id = "model") %>%  arrange(desc(adj.r.squared))
df_c5
```


```{r}
summary (modelo_experiencia)
```


```{r}
summary (modelo_educacion)
```



```{r}

ggplot(df_train, aes(x = salario_horario, y = nivel_ed, fill = nivel_ed)) + 
  geom_density_ridges() + labs(title = "Gráfico 1: Distribución nivel educativo y salario") 

```

```{r}

ggplot(data = df_train, aes(x = experiencia_potencial, y= salario_horario, color = asistencia_educacion)) +
  geom_point(alpha = 0.75) + # agregamos transparencia a los puntos
  labs(title = "Gráfico 2: Scatter experiencia y salario horario según asistencia educativa") + 
  theme(legend.position = 'none') + 
  facet_wrap(~ asistencia_educacion)

```

Con el primer modelo se busca hacer hincapié entre las variables relativas a la educación, tratando de encontrar relaciones entre las mismas que como estimadores individuales no serían posible de ser captadas. 
educacion * nivel_ed: Esta interacción entre años de educación (educación) y el nivel educativo (nivel_ed) permite modelar cómo el impacto de los años de educación sobre el salario puede variar dependiendo del nivel educativo alcanzado.  Tener un año adicional de educación podría tener un impacto mucho mayor en los salarios de personas con educación universitaria en comparación con aquellos que solo tienen educación primaria, pues por ejemplo podría ser indicativo de capacitación de master o doctorado. Pues como se comprueba en el gráfico "Gráfico 1: Distribución nivel educativo y salario" los salarios más altos tienden a concentrarse en personas con educación superior universitaria completa
asistencia_educacion * experiencia_potencial: Se intenta capturar como la experiencia potencial puede repercutir en el salario dependiendo si la persona asistió o asiste actualmente a un establecimiento educativo. Resulta indiciario de una posible relación en el "Gráfico 2: Scatter experiencia y salario horario según asistencia educativa"






```{r}
ggplot(data = df_train, aes(x = experiencia_potencial, y= salario_horario, color = categoria_ocupacion)) +
  geom_point(alpha = 0.75) + 
  labs(title = "Gráfico 3 = Scatter para diferentes categoria_ocupacion experiencia_potencial y salario horario") + 
  theme(legend.position = 'none') + 
  facet_wrap(~ categoria_ocupacion)

```

```{r}
ggplot(data = df_train, aes(x = experiencia_potencial, y = salario_horario, color = tipo_establecimiento)) +geom_jitter()+labs(title = "Gráfico 4: Scatter de categoría ocupacional según experiencia potencial y salario horario ") +
  facet_wrap(~ tipo_establecimiento)

```

```{r}
ggplot(df_train, aes(x = experiencia_potencial, y = categoria_ocupacion, fill = categoria_ocupacion)) + 
  geom_density_ridges()

```

Con el segundo modelo se centra la atención en las relaciones entre variables relativas al trabajo y la experiencia  y como impactan en el salario 
experiencia_potencial * categoria_ocupacion: se busca determinar como la experiencia en los salarios podría ser diferente para las personas que trabajan en distintas categorías ocupacionales, conforme se puede visualizar la tendencia en el "Gráfico 3 = Scatter para diferentes categoria_ocupacion experiencia_potencial y salario horario"
experiencia_potencial * tipo_establecimiento: este estimador analiza como la experiencia impacta de distinta manera dependiendo si los lugares donde se trabaja son establecimiento públicos o privados. Esto se puede visualizar preliminarmenete en el "Gráfico 4: Scatter de categoría ocupacional según experiencia potencial y salario horario "



### Evaluación en train

```{r}
df_train_c3 = df_train %>%  mutate (exp_pot_2 = I(experiencia_potencial^2)) %>% mutate(sexo = if_else(sexo == "Mujer", TRUE, FALSE)) %>%  mutate(sexo_x_años_ed = sexo * educacion) %>% mutate(log_salario_horario = log(salario_horario))
```


```{r}
df_prediccion_modelo_educacion_tr = augment(modelo_educacion, newdata = df_train) 
df_prediccion_modelo_experiencia_tr = augment (modelo_experiencia, newdata = df_train)
df_prediccion_modelo_modelo_c3_tr = augment (modelo_edad_3, newdata = df_train_c3)
df_prediccion_modelo_modelo_c4_tr = augment (modelo_c4, newdata = df_train_c3)
```



```{r}

df_prediccion_modelo_educacion_tr = df_prediccion_modelo_educacion_tr %>%  mutate(fitted_antilog = exp(.fitted))
df_prediccion_modelo_experiencia_tr = df_prediccion_modelo_experiencia_tr %>%  mutate(fitted_antilog = exp(.fitted))
df_prediccion_modelo_modelo_c4_tr = df_prediccion_modelo_modelo_c4_tr %>% mutate(fitted_antilog = exp(.fitted))

```


```{r}
metricas_m_ed = metrics(data = df_prediccion_modelo_educacion_tr, truth = salario_horario, estimate = fitted_antilog) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Educación")

metricas_m_ex = metrics(data = df_prediccion_modelo_experiencia_tr, truth = salario_horario, estimate = fitted_antilog) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Experiencia")

metricas_m_c4 = metrics(data = df_prediccion_modelo_modelo_c4_tr, truth = salario_horario, estimate = fitted_antilog) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Modelo C4")

metricas_m_c3 = metrics(data = df_prediccion_modelo_modelo_c3_tr, truth = salario_horario, estimate = .fitted) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Modelo C3")

tabla_metricas_train = bind_rows(metricas_m_ed, metricas_m_ex, metricas_m_c4, metricas_m_c3) %>%  arrange(., .metric)
tabla_metricas_train
```

### Evaluación en test

```{r}
df_test_c3 = df_test %>%  mutate (exp_pot_2 = experiencia_potencial ** 2) %>% mutate(sexo = if_else(sexo == "Mujer", TRUE, FALSE)) %>%  mutate(sexo_x_años_ed = sexo * educacion) %>% mutate(log_salario_horario = log(salario_horario))

```


```{r}
df_prediccion_modelo_educacion = augment(modelo_educacion, newdata = df_test) 
df_prediccion_modelo_experiencia = augment (modelo_experiencia, newdata = df_test)
df_prediccion_modelo_modelo_c3 = augment (modelo_edad_3, newdata = df_test_c3)
df_prediccion_modelo_modelo_c4 = augment (modelo_c4, newdata = df_test_c3)
```



```{r}

df_prediccion_modelo_educacion = df_prediccion_modelo_educacion %>%  mutate(fitted_antilog = exp(.fitted))
df_prediccion_modelo_experiencia = df_prediccion_modelo_experiencia %>%  mutate(fitted_antilog = exp(.fitted))
df_prediccion_modelo_modelo_c4 = df_prediccion_modelo_modelo_c4 %>% mutate(fitted_antilog = exp(.fitted))


eval_m_ed = df_prediccion_modelo_educacion$fitted_antilog
eval_m_ex = df_prediccion_modelo_experiencia$fitted_antilog
eval_m_c4 = df_prediccion_modelo_experiencia$fitted_antilog
eval_m_c3 = df_prediccion_modelo_modelo_c3$.fitted
```


```{r}
metricas_m_ed = metrics(data = df_prediccion_modelo_educacion, truth = salario_horario, estimate = fitted_antilog) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Educación")

metricas_m_ex = metrics(data = df_prediccion_modelo_experiencia, truth = salario_horario, estimate = fitted_antilog) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Experiencia")

metricas_m_c4 = metrics(data = df_prediccion_modelo_modelo_c4, truth = salario_horario, estimate = fitted_antilog) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Modelo C4")

metricas_m_c3 = metrics(data = df_prediccion_modelo_modelo_c3, truth = salario_horario, estimate = .fitted) %>%
  mutate(.estimate = round(.estimate, 4), modelo = "Modelo C3")

tabla_metricas_test = bind_rows(metricas_m_ed, metricas_m_ex, metricas_m_c4, metricas_m_c3) %>%  arrange(., .metric)
tabla_metricas_test
```

```{r}
tabla_metricas_test <- tabla_metricas_test %>%
  mutate(id_unico = row_number())

tabla_metricas_train <- tabla_metricas_train %>%
  mutate(id_unico = row_number())

tabla_comparada <- inner_join(tabla_metricas_test, tabla_metricas_train, by = c("id_unico"), suffix = c("_test", "_train"))

```

```{r}
vif(modelo_c4)
```

```{r}
tabla_comparada
```


Conforme se puede ver en la tabla unida de perfomance de los modelos, tomando en consideración el RMSE el modelo que mejor perfomance tiene tanto en train (872.1344) como en test (886.3392) es el Modelo de Regresión Multiple planteado en la consigna 3. Sin embargo tomando en consideración la métrica MAE el modelo que mejor perfomance tiene es el modelo Experiencia planteado en la consigna 5 con una medida de MAE 515.1099 en test y 524.1086 en train. Cabe destacar que el modelo experiencia es el que mejores puntajes de R2 posee explicando un 20.32% de la varianza de resultados predichos en test y un 19.82% en train. Motivo de ello estimo como mejor modelo para predecir salario_horario al modelo Experiencia de la consigna 5 en la medida que mejores valores de MAE y R2 posée.


## Consigna 6

```{r}
df_outlier = read.csv("C:/Users/Admin/Documents/1_Notebook/1_Estudio/1_UBA_Maestria_DS/1_Especializacion/1_Segundo_Semestre/EEA/TP_1/Datasets/eph_train_outliers_2023.csv")
```

### Grafico de outliers

```{r}
par(mfrow = c(1, 1))

salario_combinado = data.frame(   Salario_Hora = c(df_train$salario_horario, df_outlier$salario_horario),
  Dataset = factor(c(rep('Sin Outliers', nrow(df_train)),
                     rep('Con Outliers', nrow(df_outlier))))
)

ggplot(salario_combinado, aes(x = Dataset, y = Salario_Hora, fill = Dataset)) +
  geom_boxplot() +
  labs(title = "Comparación del Salario Horario", y = "Salario Horario", x = "Dataset") +
  scale_fill_manual(values = c("skyblue", "salmon")) +  
  theme_minimal()

```

### Entrenamiento y análisis del modelo 


```{r}
modelo_multiple <- lm(formula = salario_horario ~ experiencia_potencial + I(experiencia_potencial^2), data = df_outlier)


modelo_mincer = lm(formula = salario_horario ~ educacion +experiencia_potencial + I(experiencia_potencial^2) + sexo + sexo * educacion, data= df_outlier)
                   
modelo_multiple_robusto = lmrob(formula = salario_horario ~ experiencia_potencial + I(experiencia_potencial^2), data = df_outlier)

lista_modelos_c6 = list(modelo_multiple=modelo_multiple,modelo_mincer=modelo_mincer, modelo_multiple_robusto=modelo_multiple_robusto)

```



```{r}
summary(modelo_multiple)
```

```{r}
summary(modelo_mincer)
```

```{r}
summary (modelo_multiple_robusto)
```

Modelo de regresión multiple: se observa alta significancia de los estimadores experiencia_potencial e I(experiencia_potencial^2). Sin embargo el modelo presenta un R-Squared extremadamente bajo, explicando segun los valores de R2 el modelo el 0.57% de la varianza total y 0.55% segun el R2 ajustado. Se remarca la presencia de outliers en los residuos máximos con valor 82255 y un error residual estandar (1309) cercano al triple del modelo robusto.

Modelo de Mincer: presenta alta significancia de los estimadores educación, experiencia_potencial y I(experiencia_potencial^2) con p-values menores a 0.05. Sin embargo los coeficientes sexoVaron y educacion:sexoVaron presentan p-values no significativos con valores superiores a 0.05. Cabe recalcar que si bien el ajusted R muestra que este modelo es mejor que el modelo de regresión múltiple al registrar valores del 10.31% aun son valores bajos para explicar la variabilidad total de la variable dependiente. Destaco que si bien mejora el valor del error residual estándar 1243 en comparación con el modelo múltiple robusto continua en comparativamente valores altos con el modelo robusto .

Modelo_multiple_robusto: Todos los coeficientes son altamente significativos p-values < 0.001). Esto indica que existe evidencia estadística sólida para afirmar que estas variables están asociadas con el salario horario.Los altos valores absolutos de los estadísticos t refuerzan la significancia de los coeficientes. El modelo explica aproximadamente el 1.9% de la variabilidad en el salario horario, mejorando prácticamente el triple que los valores registrados en el modelo de regresión multiple. 
En cuanto a valores atípicos 298 observaciones fueron identificadas como outliers con pesos prácticamente cero |weight|=0 (<8.5e-06). Estas observaciones tuvieron una influencia mínima en la estimación de los coeficientes debido a sus pesos casi en valores cero. De esta manera el modelo robusto identifica y reduce el impacto de estos valores atípicos eficazmente.

```{r}
df_evaluacion_train_6 = map(.x = lista_modelos_c6, .f = augment, newdata = df_outlier) 
map_dfr(.x = df_evaluacion_train_6, .f = rmse, truth = salario_horario, estimate = .fitted, .id="modelo") %>% arrange(.estimate)
```
```{r}
df_evaluacion_train_6 = map(.x = lista_modelos_c6, .f = augment, newdata = df_outlier) 
map_dfr(.x = df_evaluacion_train_6, .f = mae, truth = salario_horario, estimate = .fitted, .id="modelo") %>% arrange(.estimate)
```
```{r}
df_evaluacion_test_6 = map(.x = lista_modelos_c6, .f = augment, newdata = df_test)
map_dfr(.x = df_evaluacion_test_6, .f = rmse, truth = salario_horario, estimate = .fitted, .id="modelo") %>% arrange(.estimate)
```
```{r}
df_evaluacion_test_6 = map(.x = lista_modelos_c6, .f = augment, newdata = df_test)
map_dfr(.x = df_evaluacion_test_6, .f = mae, truth = salario_horario, estimate = .fitted, .id="modelo") %>% arrange(.estimate)
```
Se concluye a partir de los resultados obtenidos que el Modelo Mincer tiene el menor RMSE, lo que indica un mejor ajuste a los datos de entrenamiento.El Modelo Mincer es superior en términos de RMSE y MAE tanto en el conjunto de entrenamiento como en el de prueba.
Incluir más variables relevantes mejoró el rendimiento del modelo. El Modelo Mincer al incluir la educación, el sexo y una interacción entre sexo y educación, además de la experiencia y su cuadrado capto más variabilidad de la variable dependiente. El Modelo Múltiple Robusto a pesar de manejar outliers mediante regresión robusta, no superó al Modelo Mincer en términos de rendimiento en la predicción.
Comparando ahora propiamente el modelo multiple robusto y el multiple no robusto. La regresión robusta asigna pesos bajos o cero a las observaciones que identifica como outliers. Al hacer esto no intenta minimizar los residuos de esas observaciones, ya que se consideran poco confiables. Esto puede resultar en residuos más grandes en las observaciones con pesos bajos, aumentando el RMSE total en el conjunto de entrenamiento y test. Asimismo, es posible que el modelo robusto esté asignando pesos bajos o cero a observaciones que no son verdaderos outliers y por ende subajustando. Esto puede ocurrir si las observaciones tienen residuos grandes debido a variabilidad natural o a características específicas que no son capturadas por el modelo pero sí por el modelo de Mincer. Por otro el modelo robusto obtuvo mejores valores de MAE ya que los errores grandes (de los outliers) no se amplifican al cuadrado y por ende repercuten menos en esta métrica.